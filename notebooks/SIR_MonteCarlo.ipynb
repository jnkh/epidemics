{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our birth process satisfies:\n",
    "$$\\dot{y} = x f(y) - \\beta y$$\n",
    "or\n",
    "$$\\dot{y} = s(y) y, \\; s(y) = \\frac{f(y)}{y} - \\beta$$\n",
    "\n",
    "At any given time, we have $n$ individuals. Within a small time $dt$ Each of these individuals gives birth with probability $(1 + \\frac{f(y)}{y})dt$ and dies with probability $(1 + \\beta)dt$. Thus the net change is $\\Delta n_{+} \\sim Binom(n,(1 + \\frac{f(y)}{y})dt)$ and $\\Delta n_{-} \\sim Binom(n,(1 + \\beta) dt)$. The overall change is then\n",
    "$$\\Delta n = \\Delta n_{+} - \\Delta n_{-}$$\n",
    "\n",
    "\n",
    "If we assume $n \\gg 1$ but both $|1 + \\frac{f(y)}{y}|,|1 + \\beta| \\ll \\frac{1}{dt}$, Then we can approximate this with a poisson distribution:\n",
    "$$\\Delta n_{+} \\sim Poisson(n \\frac{f(y)}{y} dt)$$\n",
    "and\n",
    "$$\\Delta n_{-} \\sim Poisson(n \\beta dt)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For the random variables $\\Delta n_{\\pm}$ we can then compute the mean and variance. For a binomial random variable with parameters $n$ and $p$, the mean is given by $n p$ and the variance by $n p (1-p)$. For small $p$, these both become $n p$. Thus we have\n",
    "$$E[\\Delta n] = E[\\Delta n_{+}] - E[\\Delta n_{-}] = n (\\frac{f(y)}{y} - \\beta) dt$$\n",
    "and\n",
    "$$Var[\\Delta n] = Var[\\Delta n_{+}] + Var[\\Delta n_{-}] = n (2 + \\frac{f(y)}{y} + \\beta) dt\\;.$$\n",
    "In continuous space this means\n",
    "$$E[\\delta y] = y (\\frac{f(y)}{y} - \\beta) dt \\equiv a(y) dt$$\n",
    "and\n",
    "$$Var[\\delta y] = \\frac{1}{N} y (2 + \\frac{f(y)}{y} + \\beta) dt \\equiv b(y) dt$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from graph_reciprocity import *\n",
    "from nonlinear_selection import *\n",
    "from graph_epidemic import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julian/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: RuntimeWarning: divide by zero encountered in divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/julian/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: RuntimeWarning: invalid value encountered in multiply\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "def get_y_eff(y,k):\n",
    "    return y*(1 + (1-y)/(y*k))\n",
    "\n",
    "def get_s_eff(y,alpha,beta,k):\n",
    "    return alpha*get_y_eff(y,k) - beta\n",
    "\n",
    "\n",
    "y_range = arange(0,1,0.01)\n",
    "plot(y_range,y_range)\n",
    "plot(y_range,get_y_eff(y_range,k_sparse))\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick the parameters $n_n = N y_n$, $c_r \\equiv \\frac{4 \\alpha}{N \\beta^2}$, and $N$. This uniquely determines $\\alpha$ and $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 6.4 1.6\n",
      "0.0\n",
      "y_n = 0.25, y_- = 0.0366116523517, y_+ = 0.213388347648, y_p = 0.278093108924, critical determinant = 0.5\n",
      "n_n = 5.0\n"
     ]
    }
   ],
   "source": [
    "n_n = 5\n",
    "c_r = 0.5\n",
    "N = 20\n",
    "beta = 4.0/(c_r*n_n)\n",
    "alpha = (N*beta)/n_n\n",
    "k_sparse = 4.0\n",
    "print N,alpha,beta\n",
    "print (beta/alpha - 1.0/k_sparse)/(1 - 1.0/k_sparse)\n",
    "\n",
    "y_n, y_minus,y_plus,y_p,critical_determinant = get_parameters(N,alpha,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 6.4 1.6\n",
      "y_n = 0.25, y_- = 0.0366116523517, y_+ = 0.213388347648, y_p = 0.278093108924, critical determinant = 0.5\n",
      "n_n = 5.0\n"
     ]
    }
   ],
   "source": [
    "plot_schematic(n_n,c_r,N,4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_n = 0.25, y_- = 0.0366116523517, y_+ = 0.213388347648, y_p = 0.278093108924, critical determinant = 0.5\n",
      "n_n = 5.0\n",
      "T_ave = 0.594230769231, P_fix = 0.0\n",
      "y_n = 0.25, y_- = 0.0366116523517, y_+ = 0.213388347648, y_p = 0.278093108924, critical determinant = 0.5\n",
      "n_n = 5.0\n",
      "T_ave = 0.46027027027, P_fix = 0.0\n",
      "y_n = 0.25, y_- = 0.0366116523517, y_+ = 0.213388347648, y_p = 0.278093108924, critical determinant = 0.5\n",
      "n_n = 5.0\n",
      "T_ave = 0.627837837838, P_fix = 0.0\n",
      "0.0309822038632\n"
     ]
    }
   ],
   "source": [
    "k = N- 1\n",
    "k_sparse = 4.0\n",
    "num_trials_well_mixed = 20\n",
    "num_trials = 50\n",
    "regular = True\n",
    "plotting = False\n",
    "epidemic_sizes,fixed = run_epidemics(N,alpha,beta,num_trials=num_trials_well_mixed,plotting=plotting)\n",
    "epidemic_sizes_g, fixed_g = run_epidemics(N,alpha,beta,num_trials=num_trials,plotting=plotting,\\\n",
    "                                       trajectory_fn = lambda a,b,c: simulate_graph_trajectory_adaptive(a,b,c,k=k,regular= regular))\n",
    "# #epidemic_sizes_g2, fixed_g2 = run_epidemics(N,alpha,beta,num_trials=num_trials,plotting=1,\\\n",
    "#                                       trajectory_fn = lambda a,b,c: simulate_graph_trajectory_adaptive(a,b,c,k=k/2.0))\n",
    "epidemic_sizes_g5, fixed_g5 = run_epidemics(N,alpha,beta,num_trials=num_trials,plotting=plotting,\\\n",
    "                                      trajectory_fn = lambda a,b,c: simulate_graph_trajectory_adaptive(a,b,c,k=k_sparse,regular=regular))\n",
    "\n",
    "#print (1.0/N)/y_p\n",
    "print P_fix(1.0/N,alpha,beta,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e_sizes = epidemic_sizes_g\n",
    "fixed_curr = fixed_g\n",
    "\n",
    "#close(1)\n",
    "figure(3)\n",
    "hold(1)\n",
    "nbins = 40\n",
    "bins = np.logspace(0,log10(max(e_sizes[fixed_curr == 0])),nbins)\n",
    "hist(e_sizes[fixed_curr == 0],log=True,bins=bins,alpha=0.4,normed=True,label='simulation')\n",
    "xlabel('$w$',size=20)\n",
    "ylabel('$P(w)$',size=20)\n",
    "gca().set_xscale('log')\n",
    "w_range = np.logspace(0,log10(max(e_sizes[fixed_curr == 0])))\n",
    "P_w_th_range = P_w_th(w_range,s(sqrt(w_range)/N,alpha,beta))\n",
    "P_w_th_range_eff = P_w_th(w_range,get_s_eff(sqrt(w_range)/N,alpha,beta,k_sparse))\n",
    "\n",
    "def normed_distribution(x,px):\n",
    "    return px/sum(diff(x)*px[:-1])\n",
    "\n",
    "\n",
    "#normed = integrate.quad(lambda x: P_w_th(x,0),min(epidemic_sizes[fixed_curr==0]),max(epidemic_sizes[fixed_curr==0]))[0]\n",
    "plot(w_range,normed_distribution(w_range,P_w_th_range),'-r',label=r'theory')#$P(w) \\sim e^{- s(\\sqrt{w})^2 w/4} w^{-3/2}/(1 + s(\\sqrt{w}))$ (theory)')\n",
    "plot(w_range,normed_distribution(w_range,P_w_th_range_eff),'-g',label=r'effective theory')#$P(w) \\sim e^{- s(\\sqrt{w})^2 w/4} w^{-3/2}/(1 + s(\\sqrt{w}))$ (theory)')\n",
    "\n",
    "#plot(w_range,s(sqrt(w_range)/N,alpha,beta)**2*w_range/4.0,label=r'$s(\\sqrt{w})^2 w /4$')\n",
    "axvline((2*y_p*N)**2,color = 'k',label=r'$w=4(y_p N)^2$')\n",
    "axvline((2*y_n*N)**2,color = 'k',label=r'$w=4(y_n N)^2$',linestyle='--')\n",
    "grid()\n",
    "if (y_minus > 0):\n",
    "    axvline((2*y_minus*N)**2,color = 'r',label=r'$w=4(y_- N)^2$')\n",
    "#legend(prop={'size':15},loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x9350890>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure()\n",
    "plot(w_range,normed_distribution(w_range,P_w_th_range),'-r',label=r'theory')#$P(w) \\sim e^{- s(\\sqrt{w})^2 w/4} w^{-3/2}/(1 + s(\\sqrt{w}))$ (theory)')\n",
    "plot(w_range,normed_distribution(w_range,P_w_th_range_eff),'-g',label=r'effective theory')#$P(w) \\sim e^{- s(\\sqrt{w})^2 w/4} w^{-3/2}/(1 + s(\\sqrt{w}))$ (theory)')\n",
    "plot(w_range,s(sqrt(w_range)/N,alpha,beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the theoretical prediction\n",
    "$$P(W = w) = \\frac{ e^{- s^2 w/4} w^{-3/2}}{2 \\sqrt{\\pi} (1 + s)}$$\n",
    "alongside the simulation results. We find that the distribution follows the power law until the epidemics become as large as the selection threshold. The relevant scale is when\n",
    "$\\frac{s^2 w}{4} \\sim 1$ or $w \\sim \\frac{4}{s^2}$. We then find an exponential cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16683350>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure()\n",
    "w_range = np.logspace(0,log10(100*max(epidemic_sizes[fixed == 0])))\n",
    "semilogx(w_range,(s(sqrt(w_range)/N,alpha,beta)),label=r'$s(\\sqrt{w})$')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixation Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_n = 0.8, y_- = -1, y_+ = -1, y_p = 2.02480768093, critical determinant = 15.5\n",
      "n_n = 8.0\n",
      "T_ave = 2.06086665613, P_fix = 0.0919\n",
      "y_n = 0.479587400255, y_- = -1, y_+ = -1, y_p = 1.21384031464, critical determinant = 15.5\n",
      "n_n = 8.0\n",
      "T_ave = 2.51221729755, P_fix = 0.0542\n",
      "y_n = 0.287505093104, y_- = -1, y_+ = -1, y_p = 0.727678151029, critical determinant = 15.5\n",
      "n_n = 8.0\n",
      "T_ave = 2.9035529038, P_fix = 0.0365\n",
      "y_n = 0.172354775203, y_- = -1, y_+ = -1, y_p = 0.436231590843, critical determinant = 15.5\n",
      "n_n = 8.0\n",
      "T_ave = 3.18594805218, P_fix = 0.035\n",
      "y_n = 0.103323973201, y_- = -1, y_+ = -1, y_p = 0.261513968202, critical determinant = 15.5\n",
      "n_n = 8.0\n",
      "T_ave = 3.28262359376, P_fix = 0.0337\n",
      "y_n = 0.0619410946145, y_- = -1, y_+ = -1, y_p = 0.156773505176, critical determinant = 15.5\n",
      "n_n = 8.0\n",
      "T_ave = 3.40225079972, P_fix = 0.0359\n",
      "y_n = 0.0371327106689, y_- = -1, y_+ = -1, y_p = 0.0939832472201, critical determinant = 15.5\n",
      "n_n = 8.0\n",
      "T_ave = 3.30978070411, P_fix = 0.0343\n",
      "y_n = 0.0222604752177, y_- = -1, y_+ = -1, y_p = 0.0563414765023, critical determinant = 15.5\n",
      "n_n = 8.0\n",
      "T_ave = 3.41094573861, P_fix = 0.0328\n",
      "y_n = 0.0133448042976, y_- = -1, y_+ = -1, y_p = 0.0337758278028, critical determinant = 15.5\n",
      "n_n = 8.0\n",
      "T_ave = 3.41305517416, P_fix = 0.0332\n",
      "y_n = 0.008, y_- = -1, y_+ = -1, y_p = 0.0202480768093, critical determinant = 15.5\n",
      "n_n = 8.0\n",
      "T_ave = 3.26201182584, P_fix = 0.0293\n"
     ]
    }
   ],
   "source": [
    "N_range = logspace(log10(10),log10(1000),10)\n",
    "P_fix_range = zeros_like(N_range)\n",
    "P_fix_range_th = zeros_like(N_range)\n",
    "for i,N_curr in enumerate(N_range):\n",
    "    beta = 4/(c_r*n_n)\n",
    "    alpha = (N_curr*beta)/n_n\n",
    "    P_fix_range_th[i] = P_fix(1.0/N_curr,alpha,beta,N_curr)\n",
    "    epidemic_sizes,fixed = run_epidemics(N_curr,alpha,beta,num_trials=10000,plotting=0)\n",
    "    P_fix_range[i] = 1.0*sum(fixed)/len(fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x13192450>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglog(N_range,P_fix_range_th,'-',label='theory')\n",
    "loglog(N_range,P_fix_range,'-o',label='simulation')\n",
    "legend()\n",
    "xlabel(r'$N$')\n",
    "ylabel(r'$P_{fix}(N)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x6bcfc10>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(N_range,P_fix_range_th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main TODOS:\n",
    "\n",
    "- Make simulation faster\n",
    "    - run on larger number of nodes to reduce finite size effects\n",
    "- write up our theory and results so far\n",
    "    - including next steps \n",
    "        - Test whether the assumptions in the derivation are true $<...>_S = <...>$\n",
    "        - Test whether the cutoff of P(W = w) actually corresponds to the point of y_-\n",
    "        - Look at distribution of P(y) from diffusion equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "- Look at derivation for $P(W = w)$\n",
    "- Is $W$ actually the total number that have lived? Only if death rate $\\approx 1$\n",
    "- debug $s(w)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Learn about node clustering algorithms\n",
    "- Figure out whether they are well represented by hierarchical graphs of fully connected cliques.\n",
    "- Random Network Model: try to understand the variance of number of infecteds, etc.\n",
    "\n",
    "- What fraction of the nodes are above the network?\n",
    "\n",
    "- We expect better positive selection at low frequencies (variance causes some nodes to be above threshold), but worse selection at higher frequencies (locality?). Need to compare to a large (so that finite size effects don't matter), fully connected graph."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
